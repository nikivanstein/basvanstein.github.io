{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publications markdown generator for academicpages\n",
    "\n",
    "Takes a set of bibtex of publications and converts them for use with [academicpages.github.io](academicpages.github.io). This is an interactive Jupyter notebook ([see more info here](http://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html)). \n",
    "\n",
    "The core python code is also in `pubsFromBibs.py`. \n",
    "Run either from the `markdown_generator` folder after replacing updating the publist dictionary with:\n",
    "* bib file names\n",
    "* specific venue keys based on your bib file preferences\n",
    "* any specific pre-text for specific files\n",
    "* Collection Name (future feature)\n",
    "\n",
    "TODO: Make this work with other databases of citations, \n",
    "TODO: Merge this with the existing TSV parsing solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pybtex\n",
      "  Using cached pybtex-0.24.0-py2.py3-none-any.whl (561 kB)\n",
      "Requirement already satisfied: six in /home/neocortex/.local/lib/python3.10/site-packages (from pybtex) (1.16.0)\n",
      "Collecting latexcodec>=1.0.4\n",
      "  Using cached latexcodec-2.0.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting PyYAML>=3.01\n",
      "  Using cached PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n",
      "Installing collected packages: PyYAML, latexcodec, pybtex\n",
      "Successfully installed PyYAML-6.0.1 latexcodec-2.0.1 pybtex-0.24.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.10 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/bin/pip3.10 install pybtex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybtex.database.input import bibtex\n",
    "import pybtex.database.input.bibtex \n",
    "from time import strptime\n",
    "import string\n",
    "import html\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: incorporate different collection types rather than a catch all publications, requires other changes to template\n",
    "publist = {\n",
    "    \"preprints\": {\n",
    "        \"file\" : \"preprints.bib\",\n",
    "        \"venuekey\": \"journal\",\n",
    "        \"venue-pretext\": \"Preprint on \",\n",
    "        \"collection\" : {\"name\":\"publications\",\n",
    "                        \"permalink\":\"/publication/\"}\n",
    "        \n",
    "    },\n",
    "    \"proceeding\": {\n",
    "        \"file\" : \"proceedings.bib\",\n",
    "        \"venuekey\": \"booktitle\",\n",
    "        \"venue-pretext\": \"\",\n",
    "        \"collection\" : {\"name\":\"publications\",\n",
    "                        \"permalink\":\"/publication/\"}\n",
    "        \n",
    "    },\n",
    "    \"journal\":{\n",
    "        \"file\": \"pubs.bib\",\n",
    "        \"venuekey\" : \"journal\",\n",
    "        \"venue-pretext\" : \"\",\n",
    "        \"collection\" : {\"name\":\"publications\",\n",
    "                        \"permalink\":\"/publication/\"}\n",
    "    } \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_escape_table = {\n",
    "    \"&\": \"&amp;\",\n",
    "    '\"': \"&quot;\",\n",
    "    \"'\": \"&apos;\"\n",
    "    }\n",
    "\n",
    "def html_escape(text):\n",
    "    \"\"\"Produce entities within text.\"\"\"\n",
    "    return \"\".join(html_escape_table.get(c,c) for c in text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Qi'] ['Huang']\n",
      "['Roy'] ['Winter']\n",
      "['Bas'] ['Stein']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "['Anna'] ['Kononova']\n",
      "SUCESSFULLY PARSED huang2022multi: \" Multi-surrogate Assisted Efficient Global Optimization for D ... \"\n",
      "['Bas'] ['Stein']\n",
      "['Diederick'] ['Vermetten']\n",
      "['Fabio'] ['Caraffini']\n",
      "['Anna'] ['Kononova']\n",
      "SUCESSFULLY PARSED van2023deep: \" Deep-BIAS: Detecting Structural Bias using Explainable AI  \"\n",
      "['Bas'] ['Stein']\n",
      "['Fu'] ['Long']\n",
      "['Moritz'] ['Frenzel']\n",
      "['Peter'] ['Krause']\n",
      "['Markus'] ['Gitterle']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "SUCESSFULLY PARSED van2023doe2vec: \" DoE2Vec: Deep-learning Based Features for Exploratory Landsc ... \"\n",
      "['Fu'] ['Long']\n",
      "['Diederick'] ['Vermetten']\n",
      "['Anna'] ['Kononova']\n",
      "['Roman'] ['Kalkreuth']\n",
      "['Kaifeng'] ['Yang']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "['Niki'] ['Stein']\n",
      "SUCESSFULLY PARSED long2023challenges: \" Challenges of ELA-guided Function Evolution using Genetic Pr ... \"\n",
      "['Kirill'] ['Antonov']\n",
      "['Anna'] ['Kononova']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "['Niki'] ['Stein']\n",
      "SUCESSFULLY PARSED antonov2023representation: \" Representation-agnostic distance-driven perturbation for opt ... \"\n",
      "['Niki'] ['Stein']\n",
      "['Diederick'] ['Vermetten']\n",
      "['Anna'] ['Kononova']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "SUCESSFULLY PARSED van2024explainable: \" Explainable Benchmarking for Iterative Optimization Heuristi ... \"\n",
      "['Qi'] ['Huang']\n",
      "['Wei'] ['Chen']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "['Niki'] ['Stein']\n",
      "SUCESSFULLY PARSED huang2024shapelet: \" Shapelet-based Model-agnostic Counterfactual Local Explanati ... \"\n",
      "['Kirill'] ['Antonov']\n",
      "['Roman'] ['Kalkreuth']\n",
      "['Kaifeng'] ['Yang']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "['Niki'] ['Stein']\n",
      "['Anna'] ['Kononova']\n",
      "SUCESSFULLY PARSED antonov2024functional: \" A Functional Analysis Approach to Symbolic Regression  \"\n",
      "['Bas'] ['Van', 'Stein']\n",
      "['Michael'] ['Emmerich']\n",
      "['Zhiwei'] ['Yang']\n",
      "SUCESSFULLY PARSED van2013fitness: \" Fitness landscape analysis of nk landscapes and vehicle rout ... \"\n",
      "['Bas'] ['Stein']\n",
      "['Hao'] ['Wang']\n",
      "['Wojtek'] ['Kowalczyk']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "['Michael'] ['Emmerich']\n",
      "SUCESSFULLY PARSED van2015optimally: \" Optimally weighted cluster kriging for big data regression  \"\n",
      "['Bas'] ['Stein']\n",
      "['Wojtek'] ['Kowalczyk']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "SUCESSFULLY PARSED van2016analysis: \" Analysis and visualization of missing value patterns  \"\n",
      "['Bas'] ['Van', 'Stein']\n",
      "['Wojtek'] ['Kowalczyk']\n",
      "SUCESSFULLY PARSED van2016incremental: \" An incremental algorithm for repairing training sets with mi ... \"\n",
      "['Bas'] ['Van', 'Stein']\n",
      "['Matthijs'] ['Van', 'Leeuwen']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "SUCESSFULLY PARSED van2016local: \" Local subspace-based outlier detection using global neighbou ... \"\n",
      "['Bas'] ['Stein']\n",
      "['Hao'] ['Wang']\n",
      "['Wojtek'] ['Kowalczyk']\n",
      "['Michael'] ['Emmerich']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "SUCESSFULLY PARSED van2016fuzzy: \" Fuzzy clustering for optimally weighted cluster kriging  \"\n",
      "['Pepijn'] ['Van', 'Heiningen']\n",
      "['Bas'] ['Stein']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "SUCESSFULLY PARSED van2016framework: \" A framework for evaluating meta-models for simulation-based  ... \"\n",
      "['Bas'] ['Van', 'Stein']\n",
      "['Matthijs'] ['Van', 'Leeuwen']\n",
      "['Hao'] ['Wang']\n",
      "['Stephan'] ['Purr']\n",
      "['Sebastian'] ['Kreissl']\n",
      "['Josef'] ['Meinhardt']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "SUCESSFULLY PARSED van2016towards: \" Towards data driven process control in manufacturing car bod ... \"\n",
      "['Sander'] ['Rijn']\n",
      "['Hao'] ['Wang']\n",
      "['Bas'] ['Stein']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "SUCESSFULLY PARSED van2017algorithm: \" Algorithm configuration data mining for cma evolution strate ... \"\n",
      "['Hao'] ['Wang']\n",
      "['Bas'] ['Stein']\n",
      "['Michael'] ['Emmerich']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "SUCESSFULLY PARSED wang2017time: \" Time complexity reduction in efficient global optimization u ... \"\n",
      "['Hao'] ['Wang']\n",
      "['Bas'] ['Stein']\n",
      "['Michael'] ['Emmerich']\n",
      "['Thomas'] ['Back']\n",
      "SUCESSFULLY PARSED wang2017new: \" A new acquisition function for Bayesian optimization based o ... \"\n",
      "['Thierry'] ['Spek']\n",
      "['Bas'] ['Stein']\n",
      "['Marcel'] ['Holst']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "SUCESSFULLY PARSED van2017multi: \" A multi-method simulation of a high-frequency bus line  \"\n",
      "['Bas'] ['Stein']\n",
      "['Hao'] ['Wang']\n",
      "['Wojtek'] ['Kowalczyk']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "SUCESSFULLY PARSED van2018novel: \" A novel uncertainty quantification method for efficient glob ... \"\n",
      "['Roy'] ['Winter']\n",
      "['Bas'] ['Stein']\n",
      "['Matthys'] ['Dijkman']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "SUCESSFULLY PARSED de2019designing: \" Designing ships using constrained multi-objective efficient  ... \"\n",
      "['Thiago'] ['Rios']\n",
      "['Patricia'] ['Wollstadt']\n",
      "['Bas'] ['Stein']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "['Zhao'] ['Xu']\n",
      "['Bernhard'] ['Sendhoff']\n",
      "['Stefan'] ['Menzel']\n",
      "SUCESSFULLY PARSED rios2019scalability: \" Scalability of learning tasks on 3D CAE models using point c ... \"\n",
      "['Thiago'] ['Rios']\n",
      "['Bernhard'] ['Sendhoff']\n",
      "['Stefan'] ['Menzel']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "['Bas'] ['Stein']\n",
      "SUCESSFULLY PARSED rios2019efficiency: \" On the efficiency of a point cloud autoencoder as a geometri ... \"\n",
      "['Bas'] ['Stein']\n",
      "['Hao'] ['Wang']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "SUCESSFULLY PARSED van2019automatic: \" Automatic configuration of deep neural networks with paralle ... \"\n",
      "['Xin'] ['Guo']\n",
      "['Bas'] ['Stein']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "SUCESSFULLY PARSED guo2019new: \" A new approach towards the combined algorithm selection and  ... \"\n",
      "['Thiago'] ['Rios']\n",
      "['Bas'] ['Stein']\n",
      "['Stefan'] ['Menzel']\n",
      "['Thomas'] ['Back']\n",
      "['Bernhard'] ['Sendhoff']\n",
      "['Patricia'] ['Wollstadt']\n",
      "SUCESSFULLY PARSED rios2020feature: \" Feature visualization for 3D point cloud autoencoders  \"\n",
      "['Yali'] ['Wang']\n",
      "['Bas'] ['Stein']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "['Michael'] ['Emmerich']\n",
      "SUCESSFULLY PARSED wang2020improving: \" Improving NSGA-III for flexible job shop scheduling using au ... \"\n",
      "['Thiago'] ['Rios']\n",
      "['Jiawen'] ['Kong']\n",
      "['Bas'] ['Stein']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "['Patricia'] ['Wollstadt']\n",
      "['Bernhard'] ['Sendhoff']\n",
      "['Stefan'] ['Menzel']\n",
      "SUCESSFULLY PARSED rios2020back: \" Back to meshes: Optimal simulation-ready mesh prototypes for ... \"\n",
      "['Bas'] ['Stein']\n",
      "['Hao'] ['Wang']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "SUCESSFULLY PARSED van2020neural: \" Neural network design: learning from neural architecture sea ... \"\n",
      "['Yali'] ['Wang']\n",
      "['Bas'] ['Stein']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "['Michael'] ['Emmerich']\n",
      "SUCESSFULLY PARSED wang2020tailored: \" A tailored NSGA-III for multi-objective flexible job shop sc ... \"\n",
      "['Roy'] ['Winter']\n",
      "['Bas'] ['Stein']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "SUCESSFULLY PARSED de2021samo: \" Samo-cobra: A fast surrogate assisted constrained multi-obje ... \"\n",
      "['B'] ['Stein']\n",
      "WARNING Missing Expected Field 'booktitle' from entry stein2018data: \" Data driven modeling \\& optimi ... \"\n",
      "['Bas'] ['Stein']\n",
      "['Fabio'] ['Caraffini']\n",
      "['Anna'] ['Kononova']\n",
      "SUCESSFULLY PARSED van2021emergence: \" Emergence of structural bias in differential evolution  \"\n",
      "['Thiago'] ['Rios']\n",
      "['Bas'] ['Stein']\n",
      "['Patricia'] ['Wollstadt']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "['Bernhard'] ['Sendhoff']\n",
      "['Stefan'] ['Menzel']\n",
      "SUCESSFULLY PARSED rios2021exploiting: \" Exploiting local geometric features in vehicle design optimi ... \"\n",
      "['Thiago'] ['Rios']\n",
      "['Bas'] ['Van', 'Stein']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "['Bernhard'] ['Sendhoff']\n",
      "['Stefan'] ['Menzel']\n",
      "SUCESSFULLY PARSED rios2021point2ffd: \" Point2FFD: learning shape representations of simulation-read ... \"\n",
      "['Koen'] ['Ponse']\n",
      "['Anna'] ['Kononova']\n",
      "['Maria'] ['Loleyt']\n",
      "['Bas'] ['Van', 'Stein']\n",
      "SUCESSFULLY PARSED ponse2021using: \" Using Machine Learning to Detect Rotational Symmetries from  ... \"\n",
      "['Diederick'] ['Vermetten']\n",
      "['Bas'] ['Stein']\n",
      "['Anna'] ['Kononova']\n",
      "['Fabio'] ['Caraffini']\n",
      "SUCESSFULLY PARSED vermetten2022analysis: \" Analysis of structural bias in differential evolution config ... \"\n",
      "['Marios'] ['Kefalas']\n",
      "['Bas'] ['Stein']\n",
      "['Mitra'] ['Baratchi']\n",
      "['Asteris'] ['Apostolidis']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "SUCESSFULLY PARSED kefalas2022end: \" An end-to-end pipeline for uncertainty quantification and re ... \"\n",
      "['Fu'] ['Long']\n",
      "['Bas'] ['Stein']\n",
      "['Moritz'] ['Frenzel']\n",
      "['Peter'] ['Krause']\n",
      "['Markus'] ['Gitterle']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "SUCESSFULLY PARSED long2022learning: \" Learning the characteristics of engineering optimization pro ... \"\n",
      "['Roy'] ['Winter']\n",
      "['Bas'] ['Stein']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "SUCESSFULLY PARSED de2022multi: \" Multi-point acquisition function for constraint parallel eff ... \"\n",
      "['Diederick'] ['Vermetten']\n",
      "['Fabio'] ['Caraffini']\n",
      "['Bas'] ['Stein']\n",
      "['Anna'] ['Kononova']\n",
      "SUCESSFULLY PARSED vermetten2022using: \" Using structural bias to analyse the behaviour of modular CM ... \"\n",
      "['Fu'] ['Long']\n",
      "['Diederick'] ['Vermetten']\n",
      "['Bas'] ['Stein']\n",
      "['Anna'] ['Kononova']\n",
      "SUCESSFULLY PARSED long2023bbob: \" BBOB Instance Analysis: Landscape Properties and Algorithm P ... \"\n",
      "['Gideon'] ['Hanse']\n",
      "['Roy'] ['Winter']\n",
      "['Bas'] ['Stein']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "SUCESSFULLY PARSED hanse2021optimally: \" Optimally weighted ensembles for efficient multi-objective o ... \"\n",
      "['Sneha'] ['Saha']\n",
      "['Thiago'] ['Rios']\n",
      "['Leandro'] ['Minku']\n",
      "['Bas'] ['Stein']\n",
      "['Patricia'] ['Wollstadt']\n",
      "['Xin'] ['Yao']\n",
      "['Thomas'] ['Back']\n",
      "['Bernhard'] ['Sendhoff']\n",
      "['Stefan'] ['Menzel']\n",
      "SUCESSFULLY PARSED saha2021exploiting: \" Exploiting generative models for performance predictions of  ... \"\n",
      "['R'] ['Winter']\n",
      "['B'] ['Stein']\n",
      "['THW'] ['B{\\\\\"a}ck']\n",
      "['V'] ['Bertram']\n",
      "SUCESSFULLY PARSED winter2021ship: \" Ship design performance and cost optimization with machine l ... \"\n",
      "['Sarah'] ['Thomson']\n",
      "['Niki'] ['Stein']\n",
      "['Daan'] ['Berg']\n",
      "['Cees'] ['Leeuwen']\n",
      "WARNING Missing Expected Field 'booktitle' from entry thomson2023opaque: \" The Opaque Nature of Intellige ... \"\n",
      "['Kirill'] ['Antonov']\n",
      "['Anna'] ['Kononova']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "['Niki'] ['Stein']\n",
      "SUCESSFULLY PARSED antonov2023curing: \" Curing ill-Conditionality via Representation-Agnostic Distan ... \"\n",
      "['Kirill'] ['Antonov']\n",
      "['Tiago'] ['Botari']\n",
      "['Teuss'] ['Tukker']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "['Niki'] ['Stein']\n",
      "['Anna'] ['Kononova']\n",
      "SUCESSFULLY PARSED antonov2023new: \" New solutions to Cooke triplet problem via analysis of attra ... \"\n",
      "['Kirill'] ['Antonov']\n",
      "['Roman'] ['Kalkreuth']\n",
      "['Kaifeng'] ['Yang']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "['Niki'] ['Stein']\n",
      "['Anna'] ['Kononova']\n",
      "SUCESSFULLY PARSED antonov2024functional: \" A functional analysis approach to symbolic regression  \"\n",
      "[\"Andr{\\\\'e}\"] ['Thomaser']\n",
      "['Marc-Eric'] ['Vogt']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "['Anna'] ['Kononova']\n",
      "['N'] ['Stein']\n",
      "['F'] ['Marcelloni']\n",
      "['HK'] ['Lam']\n",
      "['M'] ['Cottrell']\n",
      "['J'] ['Filipe']\n",
      "SUCESSFULLY PARSED thomaser2023real: \" Real-World Optimization Benchmark from Vehicle Dynamics: Spe ... \"\n",
      "['Niki'] ['Stein']\n",
      "['Sarah'] ['Thomson']\n",
      "['Anna'] ['Kononova']\n",
      "SUCESSFULLY PARSED van2024deep: \" A deep dive into effects of structural bias on cma-es perfor ... \"\n",
      "['Christian'] ['Interno']\n",
      "['Elena'] ['Raponi']\n",
      "['Niki'] ['Stein']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "['Markus'] ['Olhofer']\n",
      "['Yaochu'] ['Jin']\n",
      "['Barbara'] ['Hammer']\n",
      "SUCESSFULLY PARSED interno2024adaptive: \" Adaptive model pruning in federated learning through loss ex ... \"\n",
      "['Kirill'] ['Antonov']\n",
      "['Teus'] ['Tukker']\n",
      "['Tiago'] ['Botari']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "['Anna'] ['Kononova']\n",
      "['Niki'] ['Stein']\n",
      "SUCESSFULLY PARSED antonov2024quality: \" Quality-diversity driven robust evolutionary optimization of ... \"\n",
      "['Roy'] ['Winter']\n",
      "['Fu'] ['Long']\n",
      "['Andre'] ['Thomaser']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "['Niki'] ['Stein']\n",
      "['Anna'] ['Kononova']\n",
      "SUCESSFULLY PARSED de2024landscape: \" Landscape analysis based vs. domain-specific optimization fo ... \"\n",
      "['Qi'] ['Huang']\n",
      "['Emanuele'] ['Mezzi']\n",
      "['Osman'] ['Mutlu']\n",
      "['Miltiadis'] ['Kofinas']\n",
      "['Vidya'] ['Prasad']\n",
      "['Shadnan'] ['Khan']\n",
      "['Elena'] ['Ranguelova']\n",
      "['Niki'] ['Stein']\n",
      "SUCESSFULLY PARSED huang2024beyond: \" Beyond the veil of similarity: Quantifying semantic continui ... \"\n",
      "['Martijn'] ['Halsema']\n",
      "['Diederick'] ['Vermetten']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "['Niki'] ['Van', 'Stein']\n",
      "SUCESSFULLY PARSED halsema2024critical: \" A Critical Analysis of Raven Roost Optimization  \"\n",
      "['Ananta'] ['Shahane']\n",
      "['Niki'] ['Van', 'Stein']\n",
      "['Yingjie'] ['Fan']\n",
      "SUCESSFULLY PARSED shahane2024corridor: \" A Corridor Model Evolutionary Algorithm for Fast Converging  ... \"\n",
      "['Fu'] ['Long']\n",
      "['Moritz'] ['Frenzel']\n",
      "['Peter'] ['Krause']\n",
      "['Markus'] ['Gitterle']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "['Niki'] ['Stein']\n",
      "SUCESSFULLY PARSED long2024landscape: \" Landscape-aware automated algorithm configuration using mult ... \"\n",
      "['Sarah'] ['Thomson']\n",
      "['Quentin'] ['Renau']\n",
      "['Diederick'] ['Vermetten']\n",
      "['Emma'] ['Hart']\n",
      "['Niki'] ['Stein']\n",
      "['Anna'] ['Kononova']\n",
      "SUCESSFULLY PARSED thomson2025stalling: \" Stalling in Space: Attractor Analysis for any Algorithm  \"\n",
      "['Anthonie'] ['Schaap']\n",
      "['Sofoklis'] ['Kitharidis']\n",
      "['Niki'] ['Stein']\n",
      "SUCESSFULLY PARSED schaap2024towards: \" Towards Fairness in Machine Learning: Balancing Racially Imb ... \"\n",
      "['Suzan'] ['Al-Nassar']\n",
      "['Niki'] ['Stein']\n",
      "['Yingjie'] ['Fan']\n",
      "SUCESSFULLY PARSED al2024aco: \" ACO-NSGAII: A Novel Metaheuristics for Bi-Objective Electric ... \"\n",
      "['Niki'] ['Stein']\n",
      "['Anna'] ['V.', 'Kononova']\n",
      "['Lars'] ['Kotthoff']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "SUCESSFULLY PARSED van2025code: \" Code evolution graphs: Understanding large language model dr ... \"\n",
      "['Haoran'] ['Yin']\n",
      "['Anna'] ['Kononova']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "['Niki'] ['Stein']\n",
      "SUCESSFULLY PARSED yin2025optimizing: \" Optimizing photonic structures with large language model dri ... \"\n",
      "['Haoran'] ['Yin']\n",
      "['Anna'] ['Kononova']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "['Niki'] ['Stein']\n",
      "SUCESSFULLY PARSED yin2025controlling: \" Controlling the mutation in large language models for the ef ... \"\n",
      "['Niki'] ['Stein']\n",
      "['Anna'] ['V.', 'Kononova']\n",
      "['Haoran'] ['Yin']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "SUCESSFULLY PARSED van2025blade: \" BLADE: Benchmark suite for LLM-driven Automated Design and E ... \"\n",
      "['Niki'] ['Stein']\n",
      "['Qi'] ['Huang']\n",
      "['Elena'] ['Raponi']\n",
      "SUCESSFULLY PARSED van2025synergy: \" The Synergy of Explainable AI and Evolutionary Computation:  ... \"\n",
      "['Elena'] ['Raponi']\n",
      "['Ivan'] ['Rodriguez']\n",
      "['Niki'] ['Stein']\n",
      "SUCESSFULLY PARSED raponi2025global: \" Global Sensitivity Analysis Is Not Always Beneficial for Evo ... \"\n",
      "['Anna'] ['Kononova']\n",
      "['Diederick'] ['Vermetten']\n",
      "['Niki'] ['Stein']\n",
      "SUCESSFULLY PARSED kononova2025xai: \" XAI for Benchmarking Black-Box Metaheuristics  \"\n",
      "['Niki'] ['Stein']\n",
      "['Anna'] ['Kononova']\n",
      "SUCESSFULLY PARSED van2025introduction: \" An Introduction to the Crossroads of Explainable Artificial  ... \"\n",
      "['Niki'] ['Stein']\n",
      "['Anna'] ['Kononova']\n",
      "WARNING Missing Expected Field 'booktitle' from entry van2025explainable: \" Explainable AI for Evolutionar ... \"\n",
      "['Christiaan'] ['Lamers']\n",
      "['Ahmed'] ['Belbachir']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "['Niki'] ['Stein']\n",
      "SUCESSFULLY PARSED lamers2025leveraging: \" Leveraging Lightweight Generators for Memory Efficient Conti ... \"\n",
      "['Anna'] ['Kononova']\n",
      "['Niki'] ['Stein']\n",
      "SUCESSFULLY PARSED kononova2025structural: \" Structural bias in optimization algorithms  \"\n",
      "['Niki'] ['Stein']\n",
      "SUCESSFULLY PARSED van2025neighborhood: \" Neighborhood Adaptive Differential Evolution  \"\n",
      "['Bas'] ['Van', 'Stein']\n",
      "['Hao'] ['Wang']\n",
      "['Wojtek'] ['Kowalczyk']\n",
      "['Michael'] ['Emmerich']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "SUCESSFULLY PARSED van2020cluster: \" Cluster-based Kriging approximation algorithms for complexit ... \"\n",
      "['Alexander'] ['Zeiser']\n",
      "['Bas'] ['Stein']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "SUCESSFULLY PARSED zeiser2021requirements: \" Requirements towards optimizing analytics in industrial proc ... \"\n",
      "['Thiago'] ['Rios']\n",
      "['Bas'] ['Stein']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "['Bernhard'] ['Sendhoff']\n",
      "['Stefan'] ['Menzel']\n",
      "SUCESSFULLY PARSED rios2021multitask: \" Multitask Shape Optimization Using a 3-D Point Cloud Autoenc ... \"\n",
      "['Diederick'] ['Vermetten']\n",
      "['Bas'] ['Stein']\n",
      "['Fabio'] ['Caraffini']\n",
      "['Leandro'] ['Minku']\n",
      "['Anna'] ['Kononova']\n",
      "SUCESSFULLY PARSED vermetten2022bias: \" BIAS: a toolbox for benchmarking structural bias in the cont ... \"\n",
      "['Marios'] ['Kefalas']\n",
      "['Juan'] ['Santiago', 'Rojo', 'Jr']\n",
      "['Asteris'] ['Apostolidis']\n",
      "['Dirk'] ['Van', 'Den', 'Herik']\n",
      "['Bas'] ['Stein']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "SUCESSFULLY PARSED kefalas2022explainable: \" Explainable artificial intelligence for exhaust gas temperat ... \"\n",
      "['Roy'] ['Winter']\n",
      "['Philip'] ['Bronkhorst']\n",
      "['Bas'] ['Stein']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "SUCESSFULLY PARSED de2022constrained: \" Constrained multi-objective optimization with a limited budg ... \"\n",
      "['Bas'] ['Van', 'Stein']\n",
      "['Elena'] ['Raponi']\n",
      "['Zahra'] ['Sadeghi']\n",
      "['Niek'] ['Bouman']\n",
      "['Roeland'] ['Van', 'Ham']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "SUCESSFULLY PARSED van2022comparison: \" A comparison of global sensitivity analysis methods for expl ... \"\n",
      "['Alexander'] ['Zeiser']\n",
      "['Bekir'] ['{\\\\\"O}zcan']\n",
      "['Christoph'] ['Kracke']\n",
      "['Bas'] ['Stein']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "SUCESSFULLY PARSED zeiser2023data: \" A data-centric approach to anomaly detection in layer-based  ... \"\n",
      "['Bas'] ['Van', 'Stein']\n",
      "['Elena'] ['Raponi']\n",
      "SUCESSFULLY PARSED van2022gsareport: \" GSAreport: Easy to Use Global Sensitivity Reporting  \"\n",
      "['Alexander'] ['Zeiser']\n",
      "['Bekir'] ['{\\\\\"O}zcan']\n",
      "['Bas'] ['Stein']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "SUCESSFULLY PARSED zeiser2023evaluation: \" Evaluation of deep unsupervised anomaly detection methods wi ... \"\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "['Anna'] ['Kononova']\n",
      "['Bas'] ['Stein']\n",
      "['Hao'] ['Wang']\n",
      "['Kirill'] ['Antonov']\n",
      "['Roman'] ['Kalkreuth']\n",
      "['Jacob'] ['Nobel']\n",
      "['Diederick'] ['Vermetten']\n",
      "['Roy'] ['Winter']\n",
      "['Furong'] ['Ye']\n",
      "SUCESSFULLY PARSED back2023evolutionary: \" Evolutionary Algorithms for Parameter Optimizationâ€”Thirty Ye ... \"\n",
      "['Roy'] ['Winter']\n",
      "['Bas'] ['Milatz']\n",
      "['Julian'] ['Blank']\n",
      "['Niki'] ['Stein']\n",
      "['Thomas'] ['B{\\\\\"a}ck']\n",
      "['Kalyanmoy'] ['Deb']\n",
      "SUCESSFULLY PARSED de2024parallel: \" Parallel multi-objective optimization for expensive and inex ... \"\n",
      "['Peiwen'] ['Xing']\n",
      "['Aske'] ['Plaat']\n",
      "['Niki'] ['Stein']\n",
      "SUCESSFULLY PARSED xing2025cocomposer: \" CoComposer: LLM Multi-agent Collaborative Music Composition  \"\n",
      "['L'] ['Ferreira', 'Correia']\n",
      "['JC'] ['Goos']\n",
      "['P'] ['Klein']\n",
      "['THW'] ['B{\\\\\"a}ck']\n",
      "['AV'] ['Kononova']\n",
      "['N'] ['Stein']\n",
      "['C'] ['Wagner']\n",
      "['JM'] ['Garibaldi']\n",
      "['F'] ['Marcelloni']\n",
      "['HK'] ['Lam']\n",
      "[] ['others']\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 48\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m author \u001b[38;5;129;01min\u001b[39;00m bibdata\u001b[38;5;241m.\u001b[39mentries[bib_id]\u001b[38;5;241m.\u001b[39mpersons[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauthor\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28mprint\u001b[39m(author\u001b[38;5;241m.\u001b[39mfirst_names, author\u001b[38;5;241m.\u001b[39mlast_names)\n\u001b[0;32m---> 48\u001b[0m     citation \u001b[38;5;241m=\u001b[39m citation\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[43mauthor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfirst_names\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mauthor\u001b[38;5;241m.\u001b[39mlast_names[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m#citation title\u001b[39;00m\n\u001b[1;32m     51\u001b[0m citation \u001b[38;5;241m=\u001b[39m citation \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m html_escape(b[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for pubsource in publist:\n",
    "    parser = bibtex.Parser()\n",
    "    bibdata = parser.parse_file(publist[pubsource][\"file\"])\n",
    "\n",
    "    #loop through the individual references in a given bibtex file\n",
    "    for bib_id in bibdata.entries:\n",
    "        #reset default date\n",
    "        pub_year = \"1900\"\n",
    "        pub_month = \"01\"\n",
    "        pub_day = \"01\"\n",
    "        \n",
    "        b = bibdata.entries[bib_id].fields\n",
    "        \n",
    "        try:\n",
    "            pub_year = f'{b[\"year\"]}'\n",
    "\n",
    "            #todo: this hack for month and day needs some cleanup\n",
    "            if \"month\" in b.keys(): \n",
    "                if(len(b[\"month\"])<3):\n",
    "                    pub_month = \"0\"+b[\"month\"]\n",
    "                    pub_month = pub_month[-2:]\n",
    "                elif(b[\"month\"] not in range(12)):\n",
    "                    tmnth = strptime(b[\"month\"][:3],'%b').tm_mon   \n",
    "                    pub_month = \"{:02d}\".format(tmnth) \n",
    "                else:\n",
    "                    pub_month = str(b[\"month\"])\n",
    "            if \"day\" in b.keys(): \n",
    "                pub_day = str(b[\"day\"])\n",
    "\n",
    "                \n",
    "            pub_date = pub_year+\"-\"+pub_month+\"-\"+pub_day\n",
    "            \n",
    "            #strip out {} as needed (some bibtex entries that maintain formatting)\n",
    "            clean_title = b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\").replace(\" \",\"-\")    \n",
    "\n",
    "            url_slug = re.sub(\"\\\\[.*\\\\]|[^a-zA-Z0-9_-]\", \"\", clean_title)\n",
    "            url_slug = url_slug.replace(\"--\",\"-\")\n",
    "\n",
    "            md_filename = (str(pub_date) + \"-\" + url_slug + \".md\").replace(\"--\",\"-\")\n",
    "            html_filename = (str(pub_date) + \"-\" + url_slug).replace(\"--\",\"-\")\n",
    "\n",
    "            #Build Citation from text\n",
    "            citation = \"\"\n",
    "\n",
    "            #citation authors - todo - add highlighting for primary author?\n",
    "            for author in bibdata.entries[bib_id].persons[\"author\"]:\n",
    "                #print(author.first_names, author.last_names)\n",
    "                citation = citation+\" \"+author.first_names[0]+\" \"+author.last_names[0]+\", \"\n",
    "\n",
    "            #citation title\n",
    "            citation = citation + \"\\\"\" + html_escape(b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")) + \".\\\"\"\n",
    "\n",
    "            #add venue logic depending on citation type\n",
    "            venue = publist[pubsource][\"venue-pretext\"]+b[publist[pubsource][\"venuekey\"]].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")\n",
    "\n",
    "            citation = citation + \" \" + html_escape(venue)\n",
    "            citation = citation + \", \" + pub_year + \".\"\n",
    "\n",
    "            \n",
    "            ## YAML variables\n",
    "            md = \"---\\ntitle: \\\"\"   + html_escape(b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")) + '\"\\n'\n",
    "            \n",
    "            md += \"\"\"collection: \"\"\" +  publist[pubsource][\"collection\"][\"name\"]\n",
    "\n",
    "            md += \"\"\"\\npermalink: \"\"\" + publist[pubsource][\"collection\"][\"permalink\"]  + html_filename\n",
    "            \n",
    "            note = False\n",
    "            if \"note\" in b.keys():\n",
    "                if len(str(b[\"note\"])) > 5:\n",
    "                    md += \"\\nexcerpt: '\" + html_escape(b[\"note\"]) + \"'\"\n",
    "                    note = True\n",
    "\n",
    "            md += \"\\ndate: \" + str(pub_date) \n",
    "\n",
    "            md += \"\\nvenue: '\" + html_escape(venue) + \"'\"\n",
    "            \n",
    "            url = False\n",
    "            if \"url\" in b.keys():\n",
    "                if len(str(b[\"url\"])) > 5:\n",
    "                    md += \"\\npaperurl: '\" + b[\"url\"] + \"'\"\n",
    "                    url = True\n",
    "\n",
    "            md += \"\\ncitation: '\" + html_escape(citation) + \"'\"\n",
    "\n",
    "            md += \"\\n---\"\n",
    "\n",
    "            \n",
    "            ## Markdown description for individual page\n",
    "            if note:\n",
    "                md += \"\\n\" + html_escape(b[\"note\"]) + \"\\n\"\n",
    "\n",
    "            if url:\n",
    "                md += \"\\n[Access paper here](\" + b[\"url\"] + \"){:target=\\\"_blank\\\"}\\n\" \n",
    "            else:\n",
    "                md += \"\\nUse [Google Scholar](https://scholar.google.com/scholar?q=\"+html.escape(clean_title.replace(\"-\",\"+\"))+\"){:target=\\\"_blank\\\"} for full citation\"\n",
    "\n",
    "            md_filename = os.path.basename(md_filename)\n",
    "            # Do not overwrite already existing publications.\n",
    "            if not os.path.exists(\"../_publications/\" + md_filename):\n",
    "                with open(\"../_publications/\" + md_filename, 'w') as f:\n",
    "                    f.write(md)\n",
    "            print(f'SUCESSFULLY PARSED {bib_id}: \\\"', b[\"title\"][:60],\"...\"*(len(b['title'])>60),\"\\\"\")\n",
    "        # field may not exist for a reference\n",
    "        except KeyError as e:\n",
    "            print(f'WARNING Missing Expected Field {e} from entry {bib_id}: \\\"', b[\"title\"][:30],\"...\"*(len(b['title'])>30),\"\\\"\")\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
